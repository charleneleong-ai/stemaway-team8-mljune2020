{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stemaway NLP ML Project Overview -  Building a forum classifier for Discourse forum posts with BERT",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8xChJ6d7n+klFTxjoxS8n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charyeezy/stemaway-team8-mljune2020/blob/master/Notebooks/Stemaway_NLP_ML_Project_Overview_Building_a_forum_classifier_for_Discourse_forum_posts_with_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VxX2teO-jnV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##  **The High Level Overview:**\n",
        "**Building a forum classifier for Discourse forum posts with BERT**\n",
        "\n",
        "1. Webscrape data from at least 3 [public Discourse forums](https://www.discoursehub.com/communities/) to get text from posts and their\n",
        "associated metadata. \n",
        "2. Use a transformer based neural architecture (BERT) as a feature extractor to\n",
        "create a sequence level embedding for each post.\n",
        "3. Use similarity scores on the\n",
        "embeddings to determine topic similarity for any given set of posts using dimensionality reduction techniques.\n",
        "4. Build a forum classifier to predict the forum for any given post. \n",
        "\n",
        "Extension - \n",
        "- Build a recommendation engine to recommend similar posts for any given post.\n",
        "- Use clustering with nearest neighbour search engine to explore alternative means to classify which forum a given post came from and recommend posts. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4IvfJ60G8er",
        "colab_type": "text"
      },
      "source": [
        "### **1. Webscraping posts from a Discourse Forum**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qiqmw8p_HYaS"
      },
      "source": [
        "#### **1.1 Choosing a suitable Discourse Forum**\n",
        "\n",
        "Since BERT was trained on large text corpuses such as Wikipedia and Google Books etc, there are some things we must be mindful of when choosing a forum that will give us relatively clean performance with out-of-box weights.\n",
        "\n",
        "1. Avoid forums with low activity and low amount of users as there will most likely not enough data. If the language space of the dataset is too small, for any given post, it will be difficult to recommend something similar due to low probability of semantic similarity.\n",
        "2. Avoid forums with posts in other languages. There are definitely flavours of BERT in other languages but they will not be as performant as the BERT English model due to a naturally larger, more diverse corpus.\n",
        "3. Avoid forums with jargon or acronyms. This kind of niche language will be difficult for BERT to generate good embeddings as they'll most likely have been absent from BERT's training data (Wikipedia etc).\n",
        "4. Avoid forums with hyperlinks or embedded content that does not contain text. We can get incorporate a check in our scraper to check for this.\n",
        "5. If the forum has a extremely large volume of data, we will need to incorporate an early stopping condition in the scraper.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRS_qFLBOW-L",
        "colab_type": "text"
      },
      "source": [
        "#### **1.2 Webscraping Method**\n",
        "\n",
        "Discourse forums are Javascript websites with infinite scroll.\n",
        "\n",
        "<img src=\"https://www.accordbox.com/upload/images/infinit_scroll_workflow.original.jpg\" width=\"500\"/>\n",
        "\n",
        "There are three main libraries commonly used for webscraping - \n",
        "\n",
        "1. [**BeautifulSoup**](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) is Python library for pulling data out of HTML and XML files. It is used with Python's `requests` library to request content from web pages.\n",
        "2. [**Scrapy**](https://scrapy.org/) is a web crawling framework for to writing spiders, which define how a certain site (or a group of sites) will be scraped. The biggest feature is that it is built on Twisted, an asynchronous networking library, so Scrapy is implemented using a non-blocking (aka asynchronous) code for concurrency, which makes the spider performance extremely faster than other methods.\n",
        "3. [**Selenium**](https://www.selenium.dev/downloads/) is a framework which is designed to automate test for web applications. It provides a way for developer to write tests in a number of popular programming languages such as C#, Java, Python, Ruby, etc. The tests writen by developer can again most web browsers such as Chrome, IE and Firefox.\n",
        "\n",
        "| Framework          | Beautiful Soup                                                           | Scrapy                                                                                                                                             | Selenium                             |\n",
        "|--------------------|--------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------|\n",
        "| Javascript Support | No Javascript support, you need Web Driver like Selenium                 | It is time consuming to inspect and develop spider to simulate ajax/pjax requests                                                                  | Support javascript very well         |\n",
        "| Data Size          | Multiprocessing and threading needs to be implemented for large datasets | Asynchronous nature makes it a win for large datasets                                                                                              | Good option for small data set       |\n",
        "| Extensibility      | Not very easy to extend the project                                      | Easily able to develop custom middleware or pipeline to add custom function, easy to maintain.                                                     | Not very easy to customise or extend |\n",
        "| Ecosystem          | Not many related projects or plugins                                     | Many related projects, plugins on open source websites such as Github, and many discussions on StackOverflow can help you fix the potential issue. | Not many related projects or plugins |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_htbHMxkYQM8",
        "colab_type": "text"
      },
      "source": [
        "### Further Reading\n",
        "\n",
        "1. StemCast Deep Dive: Data Mining\n",
        "[Slides](https://docs.google.com/presentation/d/1kY1ITkC1ZH_370HB2fVyQU3Px3xsDQ3Pg-zs--uHfSc/edit?usp=sharing)\n",
        "[Video](https://www.youtube.com/watch?v=MWUx4Hs6gVg)\n",
        "2. StemCast Deep Dive: Recommender Systems - Content Based Approach\n",
        "[Slides](https://docs.google.com/presentation/d/1FjpqTOaLW1Ng0rJGR9YdoW4hR13EQ9sD4L6HDf5a5Ck/edit?usp=sharing) \n",
        "[Video](https://www.youtube.com/watch?v=JG5ZegwB_XQ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbwE7NXy-Q-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekTWdjGC-jEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}